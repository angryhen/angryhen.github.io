<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Refinedet-论文笔记 | Copain's blog</title><meta name="description" content="Refinedet 是CVPR2018的一篇论文，本人水平不高，在目标检测方面接触不多，仅以此文记录学习过程，主要内容在于对原文paper的翻译以及一些借鉴与解读"><meta name="keywords" content="算法"><meta name="author" content="Copain"><meta name="copyright" content="Copain"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="dns-prefetch" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="dns-prefetch" href="https://fonts.googleapis.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="dns-prefetch" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Refinedet-论文笔记"><meta name="twitter:description" content="Refinedet 是CVPR2018的一篇论文，本人水平不高，在目标检测方面接触不多，仅以此文记录学习过程，主要内容在于对原文paper的翻译以及一些借鉴与解读"><meta name="twitter:image" content="https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=551013663,1774317073&amp;fm=26&amp;gp=0.jpg"><meta property="og:type" content="article"><meta property="og:title" content="Refinedet-论文笔记"><meta property="og:url" content="https://angryhen.github.io/2018/12/28/%C2%96Refinedet-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><meta property="og:site_name" content="Copain's blog"><meta property="og:description" content="Refinedet 是CVPR2018的一篇论文，本人水平不高，在目标检测方面接触不多，仅以此文记录学习过程，主要内容在于对原文paper的翻译以及一些借鉴与解读"><meta property="og:image" content="https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=551013663,1774317073&amp;fm=26&amp;gp=0.jpg"><meta property="article:published_time" content="2018-12-28T09:50:42.000Z"><meta property="article:modified_time" content="2020-05-23T05:32:16.624Z"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="canonical" href="https://angryhen.github.io/2018/12/28/%C2%96Refinedet-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><link rel="prev" title="Refinedet 网络解析" href="https://angryhen.github.io/2018/12/30/%C2%96Refinedet-%E7%BD%91%E7%BB%9C%E8%A7%A3%E6%9E%90/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/disqusjs@1.2/dist/disqusjs.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简体"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: {"text":"富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善","fontSize":"15px"},
  medium_zoom: true,
  fancybox: false,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: true,
  isPhotoFigcaption: true,
  islazyload: false,
  isanchor: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><link rel="stylesheet" href="css/custom.css"><meta name="generator" content="Hexo 4.2.1"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">3</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">1</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">1</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> List</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#前述"><span class="toc-text"> 前述</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#摘要"><span class="toc-text"> 摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1introduction"><span class="toc-text"> 1.Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#one-stage-and-two-stage"><span class="toc-text"> one-stage and two-stage</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#refinedet-架构"><span class="toc-text"> Refinedet 架构</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-related-work"><span class="toc-text"> 2. Related Work</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3network-architecture-网络架构"><span class="toc-text"> 3.Network Architecture 网络架构</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#arm结构"><span class="toc-text"> ARM结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#odm"><span class="toc-text"> ODM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#transfer-connection-blocktcb"><span class="toc-text"> Transfer Connection Block(TCB)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#negative-anchor-filtering"><span class="toc-text"> Negative Anchor Filtering</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-training-and-inference"><span class="toc-text"> 4. Training and Inference</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#data-augmentation"><span class="toc-text"> Data Augmentation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#backbone-network"><span class="toc-text"> Backbone Network</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hard-negative-mining"><span class="toc-text"> Hard Negative Mining</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#optimization"><span class="toc-text"> Optimization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#inference"><span class="toc-text"> Inference</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#读后"><span class="toc-text"> 读后：</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#具体网络结构是怎么构建的呢"><span class="toc-text"> 具体网络结构是怎么构建的呢?</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=551013663,1774317073&amp;fm=26&amp;gp=0.jpg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Copain's blog</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> List</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">Refinedet-论文笔记</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date" title="发表于 2018-12-28 17:50:42"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2018-12-28</time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="post-meta__icon far fa-file-word" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">3.6k</span><span class="post-meta__separator">|</span><i class="post-meta__icon far fa-clock" aria-hidden="true"></i><span>阅读时长: 13 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p>2018.12.28 对于refinedet 网络部分的一些补充：<br />
<a href="https://www.jianshu.com/p/19896a763d1f" target="_blank" rel="noopener">https://www.jianshu.com/p/19896a763d1f</a></p>
<h1 id="前述"><a class="markdownIt-Anchor" href="#前述"></a> 前述</h1>
<p>       Refinedet 是CVPR2018的一篇论文，本人水平不高，在目标检测方面接触不多，仅以此文记录学习过程，主要内容在于对原文paper的翻译以及一些借鉴与解读。</p>
<p>论文地址：<a href="https://arxiv.org/pdf/1711.06897.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1711.06897.pdf</a></p>
<h1 id="摘要"><a class="markdownIt-Anchor" href="#摘要"></a> 摘要</h1>
<p><img src="https://upload-images.jianshu.io/upload_images/15147802-fe88be05c46d2ad3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Abstract.png" /></p>
<p>其中主要说了：<br />
<strong>1</strong>.包括了两个模块:anchor refinement mododule (<strong>ARM</strong>),<br />
　　　　　　　　object detection module(<strong>ODM</strong>)<br />
　　前者过滤掉负anchor以减少分类器的搜索空间，并且粗略调整anchor的位置和大小为后续的回归器提供更好的初始化*(类似于RPN)*，后一个模块将精确的anchor作为输入从前者进一步改进回归并预测多类标签。<br />
<strong>2</strong>.一个转移连接块:transfer connection block(<strong>TCB</strong>)<br />
<strong>3</strong>.多任务的端到端训练</p>
<blockquote>
<p><em>后面会对这些有详细的解析</em><br />
<em>同时作者给出了源码：<a href="https://github.com/sfzhang15/RefineDet" target="_blank" rel="noopener">https://github.com/sfzhang15/RefineDet</a> (caffe)</em></p>
</blockquote>
<h1 id="1introduction"><a class="markdownIt-Anchor" href="#1introduction"></a> 1.Introduction</h1>
<h2 id="one-stage-and-two-stage"><a class="markdownIt-Anchor" href="#one-stage-and-two-stage"></a> one-stage and two-stage</h2>
<p>       前３段主要介绍了目前object detection的算法框架，其中</p>
<blockquote>
<p><em>However, its detection accuracy is usually behind that of<br />
the two-stage approach, one of the main reasons being due<br />
to the class imbalance problem</em><br />
译：<strong>但是，它的检测精度通常落后于两阶段方法，其中一个主要原因是由于阶级不平衡问题</strong></p>
</blockquote>
<p>作者的观点中，描述了two-stage methods：Faster R-CNN, R-FCN, and FPNd的３个优点：</p>
<blockquote>
<p><em>(1)using two-stage structure with sampling heuristics to handle classimbalance;<br />
<strong>采用带抽样启发式的两阶段结构来处理类不平衡</strong>;<br />
(2) using two-step cascade toregress the object box parameters;<br />
<strong>使用两步级联来回归对象框参数</strong><br />
(3) using two-stage features to describe the objects<br />
<strong>使用两阶段特征来描述对象</strong></em></p>
</blockquote>
<h2 id="refinedet-架构"><a class="markdownIt-Anchor" href="#refinedet-架构"></a> Refinedet 架构</h2>
<p><img src="https://upload-images.jianshu.io/upload_images/15147802-5ea767c2b7280843.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Refinedet架构.png" /></p>
<blockquote>
<p><em>Specifically, it achieves 85.8% and 86.8% mAPs on VOC2007 and 2012, with VGG-16 network. Meanwhile, it outperforms the previously best published results from bothone-stage and two-stage approaches by achieving 41.8% AP4 on MS COCO test-dev with ResNet-101. In ad3The features in the ARM focus on<br />
distinguishing positive anchors from background. We design the TCB to transfer the features in the ARMto handle the more challenging tasks in the ODM, i.e., predict accurate object locations, sizes and multi-class labels. Based on the evaluation protocol in MS COCO [29], AP is the sindition, RefineDet is time efficient, i.e., it runs at 40.2 FPS and 24.1 FPS on a NVIDIA Titan X GPU with the input sizes 320 × 320 and 512 × 512 in inference.</em><br />
这一段详细说明了Refinedet 在<strong>VOC2007,2012上采用VGG16，在MS COCO 上采用Resnet-101</strong>，检测的结果和时间效率都优于目前公布最好的结果。</p>
</blockquote>
<p>主要做了３个贡献：<br />
１.引入了一个新颖的一阶段框架用于对象检测，由两个互连模块组成，即ARM和ODM。 这导致了性能比两阶段方法更好，同时保持一阶段方法的效率。<br />
2 .为了确保有效性，我们设计TCB以转移ARM中的特征以处理更具挑战性的任务，即在ODM中预测准确的对象位置，大小和类标签。<br />
3 .RefineDet在通用物体检测上实现了最新的最新成果（即PASCAL VOC 2007，2012和MS COCO）</p>
<h1 id="2-related-work"><a class="markdownIt-Anchor" href="#2-related-work"></a> 2. Related Work</h1>
<p>主要介绍了传统的和目前的一些目标检测算法，过。</p>
<h1 id="3network-architecture-网络架构"><a class="markdownIt-Anchor" href="#3network-architecture-网络架构"></a> 3.Network Architecture 网络架构</h1>
<p>       第一段大体讲述了Refinedet的机理，类似于ssd的一个前馈卷及神经网络</p>
<blockquote>
<p><em>Similar to SSD , RefineDet is based on a feedforward convolutional network that produces a fixed number of bounding boxes and the scores indicating the presence of different classes of objects in those boxes, followed by the non-maximum suppression to produce the final result</em></p>
</blockquote>
<p>类似于SSD，RefineDet基于前馈卷积网络，它产生固定数量的边界框，分数表示在这些框中存在不同类别的对象，然后是非极大值抑制以产生最终结果</p>
<h2 id="arm结构"><a class="markdownIt-Anchor" href="#arm结构"></a> ARM结构</h2>
<blockquote>
<p><em><strong>ARM</strong> is constructed by <strong>removing the classification layers and adding some auxiliary structures</strong> of <strong>two base networks</strong>(i.e., VGG-16 [43] and ResNet-101 [19] pretrained on ImageNet [37]) to meet our needs</em></p>
</blockquote>
<p><strong>ARM</strong>是在两个基础网络上(预训练的<strong>VGG-16</strong>和<strong>ResNet-101</strong>)，通过<strong>移除分类层和添加一些辅助的结构</strong>，达到我们的需求</p>
<h2 id="odm"><a class="markdownIt-Anchor" href="#odm"></a> ODM</h2>
<blockquote>
<p><em>The <strong>ODM</strong> is composed of the outputs of <strong>TCBs</strong> followed by the prediction layers (i.e.,the convolution layers with 3 × 3 kernel size), which generates the scores for object classes and shape offsets relative to the refined anchor box coordinates</em></p>
</blockquote>
<p><strong>ODM</strong>是由跟随在预测层（生成分类对象的分数和相对形状偏移的refined anchor box 的笛卡尔坐标）后面的TCBs的输出组成</p>
<h2 id="transfer-connection-blocktcb"><a class="markdownIt-Anchor" href="#transfer-connection-blocktcb"></a> Transfer Connection Block(TCB)</h2>
<p><img src="https://upload-images.jianshu.io/upload_images/15147802-96b5943d887b66f4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="TCB.png" /></p>
<p>        为了建立ARM和ODM的联系，我们引入TCB来将ARM中的特征图转换到ODM中，这样ODM可以共享ARM的特征。值得注意的是，从ARM中，我们只在与anchors有联系的特征图上使用TCBs。<br />
　　TCB的另一个功能是通过向传输的特征添加高级特征来集成大规模的上下文，以提高检测精度。 为了匹配它们之间的尺寸，我们使用反卷积操作来放大高级特征图并以元素方式对它们求和。 然后，我们在求和之后添加卷积层以确保检测特征的可辨性<br />
<img src="https://upload-images.jianshu.io/upload_images/15147802-8c56b7b14df19870.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="TCBS.png" /></p>
<blockquote>
<p>该网络主要有三个特点<br />
1）利用TCB模块进行类似FPN 的特征融合，提高低层语义信息，有利于小物体检测<br />
2）两步级联回归，提升框的质量，在ARM模块中利用SSD二分类网络做PRN的工作，进行粗回归调整，在ODM模块中进行位置精调。<br />
3）负样本过滤机制，文中在进行1：3的难例挖掘前先进行了负样本的过滤，当候选框的背景置信度高（大于0.99时)，直接舍去，不丢入分类器，这样能缓解样本不平衡问题，同时缩短检测速度。<br />
####Two-Step Cascaded Regression<br />
*Specifically, we associate n anchor boxes with each regularly divided cell on the feature map. The initial position of each anchor box relative to its corresponding cell is fixed.<br />
At each feature map cell, we predict four offsets of the refined anchor boxes relative to the original tiled anchors and two confidence scores indicating the presence of foreground objects in those boxes. Thus, we can yield n refined anchor boxes at each feature map cell. *</p>
</blockquote>
<p>具体来说，就是将n个anchor box与特征图上的每个规则划分的单元格相关联。 每个anchor box相对于其相应单元的初始位置是固定的。<br />
在每个特征地图单元格中，我们预测相对于原始anchor的refined anchor的四个偏移量和两个置信度分数(表示这些框中存在前景物体)。 因此，我们可以在每个特征图单元格产生n个refined anchors。获得refined anchors后，我们将其传到ODM相应的特征图中，进一步生成对象类别和准确的对象位置、尺寸。ARM和ODM中相应的特征图具有相同的维度。我们计算refined anchors的c个类别分数和四个准确的偏移量，产生c + 4的输出以完成检测任务。此过程类似于SSD 中的默认框。但是，与SSD 不同，RefineDet使用两步策略，即ARM生成refined anchor boxes，ODM采取其作为输入进一步检测，因此检测结果更精准，特别适用于小物体。</p>
<h2 id="negative-anchor-filtering"><a class="markdownIt-Anchor" href="#negative-anchor-filtering"></a> Negative Anchor Filtering</h2>
<blockquote>
<p><em>in training phase, for a refined anchor box, if its negative confidence is larger than a preset threshold θ (i.e., set θ = 0.99empirically), we will discard it in training the ODM</em></p>
</blockquote>
<p>在训练阶段，对于精确的锚箱，如果其负置信度大于预设阈值θ（即设定θ= 0.99经度），我们将在训练ODM时将其丢弃，对应上面第三个特点</p>
<h1 id="4-training-and-inference"><a class="markdownIt-Anchor" href="#4-training-and-inference"></a> 4. Training and Inference</h1>
<h2 id="data-augmentation"><a class="markdownIt-Anchor" href="#data-augmentation"></a> Data Augmentation</h2>
<p>简单的说就是通过数据增强使得模型更具鲁棒性，随机扩展并裁剪原始训练图像，随机光度失真和翻转生成训练样本。 Please refer to [ssd]<a href="http://www.cs.unc.edu/~wliu/papers/ssd.pdf" target="_blank" rel="noopener">http://www.cs.unc.edu/~wliu/papers/ssd.pdf</a> for more details.</p>
<h2 id="backbone-network"><a class="markdownIt-Anchor" href="#backbone-network"></a> Backbone Network</h2>
<p><img src="https://upload-images.jianshu.io/upload_images/15147802-e8b555ddba3d8c2d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Backbone Network.png" /><br />
骨干网络使用了在ILSVRC CLS-LOC上预先训练的VGG-16和ResNet-101，同时也可以在其他的预训练网络上working*(such as Inception V2 [22], Inception ResNet [44], and ResNeXt101 )*。</p>
<blockquote>
<p><em>we convert fc6 and fc7 of VGG-16 to convolution layers conv fc6 and conv fc7 via subsampling parameters<br />
Meanwhile, to capture high-level information and drive object detection at multiple scales,we also add two extra convolution layers (i.e., conv6 1 and conv6 2) to the end of the truncated VGG-16 and one extra residual block (i.e., res6) to the end of the truncated ResNet101, respectively.</em></p>
</blockquote>
<p>通过下采样参数(应该是吧)将<strong>VGG-16的fc6和fc7转换为卷积层conv fc6和conv fc7</strong>,同时为了在多个尺度上捕获高级信息和驱动对象检测，还在<strong>截断的VGG-16的末尾添加了两个额外的卷积层(即conv6_1和conv6_2)和一个额外的残余块(即res6)添加到截断的ResNet101的末尾。</strong></p>
<blockquote>
<p><em>Since conv4 3 and conv5 3 have different feature scales compared to other layers, we use L2 normalization [31] to scale the feature norms in conv4 3 and conv5 3 to 10 and 8, then learn the scales during back propagation</em><br />
<strong>对conv4_3以及conv5_3添加了L2 normalization层，并分别设置scale为10和8，并在反向传播中学习scale上</strong></p>
</blockquote>
<p>附上VGG16和ResNet-101的结构图<br />
<img src="https://upload-images.jianshu.io/upload_images/15147802-1d42e5209af92d12.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="VGG-16.png" /><br />
<img src="https://upload-images.jianshu.io/upload_images/15147802-fa0fd5492ba47b71.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="ResNet-50.jpg" /></p>
<p>####Anchors Design and Matching<br />
<img src="https://upload-images.jianshu.io/upload_images/15147802-0a12a9c310bfce73.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Anchors Design and Matching.png" /><br />
Anchor的设计跟SSD也是比较相似的，不同的是，这里只在4个feature layer上面提取Anchor，分别对应stride为（8，16，32，64），并且不同的feature layer匹配不同大小及尺寸的anchor，scale是stride的4倍即对应的检测尺度为，<em>以320为例子，对应的不同的layer检测的图像尺度为：[ 32， 64， 128， 256 ]，aspect ratio 有3个（0.5，1，2）</em>,同时，在训练期间阶段，我们确定之间的对应关系基于anchors和ground truth boxes的jaccard重叠率（IoU），并端到端地训练整个网络。具体来说，我们首先将每个ground truth boxes与具有最佳重叠分数的anchor boxes相匹配，然后匹配anchor重叠高于0.5的任何ground truth boxes。</p>
<h2 id="hard-negative-mining"><a class="markdownIt-Anchor" href="#hard-negative-mining"></a> Hard Negative Mining</h2>
<p><img src="https://upload-images.jianshu.io/upload_images/15147802-0888ee1dda493d7d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Hard Negative Mining.png" /><br />
在匹配步骤之后，大部分anchor boxex都是负样本的，即使在ARM时过滤了很多，类似于SSD的做法，用hard negative mining来设定正负样本的比例（一般设定为1:3），负样本不是随机选的，而是根据box的分类<strong>loss排序</strong>来选的，按照指定比例选择<strong>loss最高</strong>的那些负样本即可</p>
<p>####Loss Function<br />
这里由两部分组成：<br />
<strong>ARM</strong>：每个anchor的二分类标签<em>binary class label</em>(object is or not)<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">L_b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和其位置与大小的回归<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">L_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><br />
　　----&gt;之后，我们将具有小于阈值的负置信度的精确锚传递给ODM，以进一步预测对象类别和准确的对象位置和大小。<br />
<strong>ODM</strong>：多酚类multi-class classification损失<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">L_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和回归损失<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">L_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>
<p>需要注意的是:<br />
　　　虽然本文大致上是RPN网络和SSD的结合，但是在Faster R-CNN算法中RPN网络和检测网络的训练可以分开也可以end to end，而这里的训练方<br />
式就纯粹是end to end了，ARM和ODM两个部分的损失函数都是<strong>一起向前传递</strong>的。<br />
<img src="https://upload-images.jianshu.io/upload_images/15147802-b0df81a942aac4d6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Loss.png" /></p>
<blockquote>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>代表ARM中anchor分类的置信度和回归的坐标<br />
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>t</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">t_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>代表ODM中refined anchor分类的置信度和坐标回归<br />
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mrow><mi>a</mi><mi>r</mi><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">N_{arm}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mrow><mi>o</mi><mi>d</mi><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">N_{odm}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 代表batch中的正样本数<br />
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">L_b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 代表二分类的交叉熵loss，作判断是否有object<br />
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">L_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>代表softmax loss，多分类损失<br />
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">L_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 代表smooth L1 loss，回归损失（应该和faster-rcnn类似吧）<br />
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>l</mi><mi>i</mi><mo>∗</mo></msubsup></mrow><annotation encoding="application/x-tex">l^*_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.953104em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-2.441336em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span></span></span></span>  代表第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个anchor的ground truth的类别<br />
<strong>[<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>l</mi><mi>i</mi><mo>∗</mo></msubsup><mo>≥</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">l^*_i \geq 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.953104em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-2.441336em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>]</strong>  表示如果negative confidence大于一个阈值θ，那么返回1，否则返回0<br />
　　　　也就是说当条件满足的时候输出为1，[<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>l</mi><mi>i</mi><mo>∗</mo></msubsup><mo>≥</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">l^*_i \geq 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.953104em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-2.441336em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>]代表的是正样本，所以[<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>l</mi><mi>i</mi><mo>∗</mo></msubsup><mo>≥</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">l^*_i \geq 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.953104em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-2.441336em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>]代表的是只<br />
　　　　有正样本才会去计算坐标回归，负样本不计算。<br />
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>g</mi><mi>i</mi><mo>∗</mo></msubsup></mrow><annotation encoding="application/x-tex">g^*_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.94736em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-2.441336em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span></span></span></span>   代表第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个anchor的ground truth位置和大小</p>
</blockquote>
<p>需要注意的是下面这一点：<br />
<img src="https://upload-images.jianshu.io/upload_images/15147802-b243d45b68917080.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="notably.png" /></p>
<h2 id="optimization"><a class="markdownIt-Anchor" href="#optimization"></a> Optimization</h2>
<p><img src="https://upload-images.jianshu.io/upload_images/15147802-b34c92fff1b4dd52.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Optimization.png" /><br />
VGG-16：新添加的卷积层(onv6_1和conv6_2)，用xavier初始化参数<br />
ResNet-101：新添加的residual block, 采用均值为0，方差为0.01的高斯分布进行初始化</p>
<blockquote>
<p>default batch size = 32<br />
momentum = 0.9 (收敛快)<br />
weight decay = 0.0005  (正则项，防止过拟合)<br />
learning rate = <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>3</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{-3}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span></p>
</blockquote>
<h2 id="inference"><a class="markdownIt-Anchor" href="#inference"></a> Inference</h2>
<p>在inference阶段，ARM先过滤掉负置信度大于阈值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span></span></span>的anchor，然后refine剩余anchor的位置与大小，将refined anchor传入ODM模块进行分类，每张图像取得分高的400个图像。最终 应用NMS，jaccard重叠率限定为0.45，保证最终得到200个高分的检测结果作为最终的结果。</p>
<h1 id="读后"><a class="markdownIt-Anchor" href="#读后"></a> 读后：</h1>
<blockquote>
<p>1.感觉ARM就是和RPN的功能相差无几，ARM由多层不同尺度的特征输出，而RPN只有一个<br />
2.ODM接收来自ARM的refined anchor，类似于RPN的proposal，浅层的feature map 融合了高层feature map的信息，后预测bbox是基于每层feature map（每个蓝色矩形块）进行，最后将各层结果再整合到一起。此处提高了对小物体的检测<br />
3.TCB是将不同层次的ARM特征转化为ODM，它这里有一个回传的操作，将高层次的特征通过去卷机操作（实际是一种转置卷积），使特征图之间的尺寸匹配，然后与低层次的特征相加。</p>
</blockquote>
<h2 id="具体网络结构是怎么构建的呢"><a class="markdownIt-Anchor" href="#具体网络结构是怎么构建的呢"></a> 具体网络结构是怎么构建的呢?</h2>
<p>以特征提取网络为ResNet101，输入图像大小为320为例，在Anchor Refinement Module部分的4个灰色矩形块（feature map）的size分别是40<em>40,20</em>20,10<em>10,5</em>5，其中前三个是ResNet101网络本身的输出层，最后5<em>5输出是另外添加的一个residual block。有了特征提取的主网络后，就要开始做融合层操作了，首先是5</em>5的feature map经过一个transfer connection block得到对应大小的蓝色矩形块（P6）,transfer connection block后面会介绍 ，对于生成P6的这条支路而言只是3个卷积层而已。接着基于10*10的灰色矩形块（feature map）经过transfer connection block得到对应大小的蓝色矩形块（P5），此处的transfer connection block相比P6增加了反卷积支路，反卷积支路的输入来自于生成P6的中间层输出。P4和P3的生成与P5同理。</p>
<p>作者的backbone采用VGG16（the conv4_3, conv5_3, conv fc7, and conv6_2 feature layers）和Resnet101(res3b3, res4b22, res5c, and res6)作为ARM的四个蓝色框<br />
参考源码自定义ARM输出层为：<br />
<img src="https://upload-images.jianshu.io/upload_images/15147802-351076ad2117cc7f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="output.png" /></p>
<blockquote>
<p><em>需要注意：fc6和fc7采用conv层替代，conv6 的输入为32×32，采用dilated方式；conv7采用11卷积，输出32×32，同时增加5个类似ssd的conv输出层</em></p>
</blockquote>
<p>在此附上SSD的结构，易于对比：<br />
<img src="https://upload-images.jianshu.io/upload_images/15147802-7bd7b2a87cdadeb5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="SSD.png" /></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Copain</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://angryhen.github.io/2018/12/28/%C2%96Refinedet-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">https://angryhen.github.io/2018/12/28/Refinedet-论文笔记/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://angryhen.github.io" target="_blank">Copain's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/">论文解读</a></div><div class="post_share"><div class="social-share" data-image="/img/1000971.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2018/12/30/%C2%96Refinedet-%E7%BD%91%E7%BB%9C%E8%A7%A3%E6%9E%90/"><img class="prev_cover" src="https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=551013663,1774317073&amp;fm=26&amp;gp=0.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Refinedet 网络解析</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2018/12/30/Refinedet-网络解析/" title="Refinedet 网络解析"><img class="relatedPosts_cover" src="https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=551013663,1774317073&fm=26&gp=0.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2018-12-30</div><div class="relatedPosts_title">Refinedet 网络解析</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="disqus_thread"></div><script src="https://cdn.jsdelivr.net/npm/disqusjs@1.2/dist/disqus.js"></script><script>var dsqjs = new DisqusJS({
  shortname: '',
  siteName: "",
  identifier: '2018/12/28/Refinedet-论文笔记/',
  url: 'https://angryhen.github.io/2018/12/28/%C2%96Refinedet-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/',
  title: 'Refinedet-论文笔记',
  api: 'https://disqus.skk.moe/disqus/',
  apikey: '',
  admin: '',
  adminLabel: ''
});
</script></div></article></main><footer id="footer" style="background-image: url(https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=551013663,1774317073&amp;fm=26&amp;gp=0.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2020 By Copain</div><div class="footer_custom_text">More and More</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode far fa-moon" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script id="ribbon_piao" mobile="true" src="/js/third-party/piao.js"></script><script src="/js/third-party/activate-power-mode.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
document.body.addEventListener('input', POWERMODE);
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="/js/third-party/ClickShowText.js"></script><script src="/js/search/local-search.js"></script></body></html>